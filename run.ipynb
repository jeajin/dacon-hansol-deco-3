{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from utils.data_utils import load_data, preprocess_data, create_qa_data\n",
    "from utils.model_utils import initialize_model, create_vector_store, create_qa_chain\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# 병렬 처리 비활성화\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import site\n",
    "print(site.getsitepackages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--cfg-path\", type=str, default=None)\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def load_config(cfg_path):\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config('./configs/jj.yaml')\n",
    "train_data_path = cfg[\"paths\"][\"train_data\"]\n",
    "test_data_path = cfg[\"paths\"][\"test_data\"]\n",
    "submission_path = cfg[\"paths\"][\"submission\"]\n",
    "output_path = cfg[\"paths\"][\"output\"]\n",
    "model_name = cfg[\"model\"][\"model_name\"]\n",
    "model_path = cfg[\"model\"][\"model_path\"]\n",
    "embedding_model_name = cfg[\"model\"][\"embedding_model\"]\n",
    "prompt_template = cfg[\"prompt_template\"]\n",
    "batch_size = cfg[\"settings\"][\"batch_size\"]\n",
    "\n",
    "# load data\n",
    "train_df, test_df = load_data(train_data_path, test_data_path)\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "train_data = create_qa_data(train_df, is_train=True)\n",
    "test_data = create_qa_data(test_df, is_train=False)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# Import model\n",
    "tokenizer, model = initialize_model(model_name, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "vector_store = create_vector_store(train_data, embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Generate RAG chain\n",
    "qa_chain = create_qa_chain(vector_store, model, tokenizer, prompt_template, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataSet(Dataset):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.test_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 단순히 질문을 가져오는 것만 수행합니다\n",
    "        \n",
    "        questions = self.test_data[idx]['question']\n",
    "        return {\"query\": questions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "# DataLoader 생성\n",
    "qa_dataset = QADataSet(test_dataset)\n",
    "qa_dataloader = DataLoader(qa_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 실행 시작... 총 테스트 샘플 수: 964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 1/964 [00:41<10:58:19, 41.02s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 실행 시작... 총 테스트 샘플 수:\", len(test_data))\n",
    "test_results = []\n",
    "t=0\n",
    "# 이제 DataLoader를 사용해 배치 단위로 데이터를 처리합니다\n",
    "for batch in tqdm(qa_dataloader, desc=\"Processing\"):\n",
    "    question = [{\"query\": row} for row in batch['query']]\n",
    "    batch_results = [res[\"result\"] for res in qa_chain.batch(question)]\n",
    "    test_results += batch_results\n",
    "    if t>=1:\n",
    "        break\n",
    "    else:\n",
    "        t+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
